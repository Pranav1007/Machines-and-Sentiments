{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#nltk.download('popular', quiet=True) # for downloading packages\n",
    "#!pip3 install rake-nltk\n",
    "\n",
    "def recommend_movie_choices():\n",
    "    print(\"\\nROBO: So you want to see a new movie now right?\")\n",
    "    df_movies = pd.read_csv(\"IMDb movies.csv\")\n",
    "    df_ratings = pd.read_csv(\"IMDb ratings.csv\")\n",
    "\n",
    "    # Taking a look at all the columns in the dataframe(s)\n",
    "    #print(\"Columns for Movie Details: \\n\",df_movies.columns)\n",
    "    #print(\"Columns for Movie Rating statistics: \\n\", df_ratings.columns)\n",
    "\n",
    "    # Taking a look at the Movie Details Dataframe\n",
    "    #df_movies.head()\n",
    "\n",
    "    # Taking a look at the Movie Rating Statistics Dataframe\n",
    "    #df_ratings.head()\n",
    "\n",
    "    # Removing all the unwanted columns from the two Dataframes\n",
    "    df_movies = df_movies[['imdb_title_id','title', 'duration', 'year', 'genre', 'language', 'actors', 'director','description']]\n",
    "    df_ratings = df_ratings[['imdb_title_id', 'mean_vote', 'weighted_average_vote','median_vote', 'total_votes']]\n",
    "\n",
    "    #Again Taking a look at all the columns in the dataframe(s) after dropping unwanted columns\n",
    "    #print(\"Columns for Movie Details: \\n\",df_movies.columns)\n",
    "    #print(\"Columns for Movie Rating statistics: \\n\", df_ratings.columns)\n",
    "\n",
    "    # Merging the two dataframes and dropping all the nan values\n",
    "    df = pd.merge(df_movies, df_ratings, on='imdb_title_id')\n",
    "    #print(\"Shape, Before dropping Nan Values: \",df.shape)\n",
    "    df.dropna(inplace = True)\n",
    "    dfm = df.copy()\n",
    "    #print(\"Shape, After dropping Nan Values: \",df.shape)\n",
    "\n",
    "    df2 = df[df['language'].str.contains(r'English')]\n",
    "    #print(df2.shape)\n",
    "    df2 = df2[(df2['mean_vote'] >= 6) & (df['total_votes'] >= 1000)] # Take all English Movies with Rating greater than 6\n",
    "    #print(df2.shape)\n",
    "    df2 = df2[df2['year'] >= 1995]\n",
    "    #print(df2.shape)\n",
    "    df2[df2['title'].str.contains('123')]\n",
    "\n",
    "    df3 = df[df['language'].str.contains(r'Tamil|Kannada|Telugu|Hindi|Malayalam')]\n",
    "    #df3.shape\n",
    "    df3 = df3[(df3['mean_vote'] >= 5) & (df3['total_votes'] >= 500)]\n",
    "    df3[df3['title'].str.contains('Student')]\n",
    "    #df3.shape\n",
    "\n",
    "\n",
    "    df = pd.concat([df2,df3])\n",
    "    df = df.apply(lambda x: x.str.lower() if(x.dtype == 'O') else x)\n",
    "    df = df.drop_duplicates(subset=['title','year'], keep = False)\n",
    "\n",
    "    dfm = dfm[(dfm['mean_vote'] >= 5) & (dfm['total_votes'] >= 500)]\n",
    "    dfm = dfm.sort_values(by=['mean_vote'],ascending = False)\n",
    "    dfm = dfm.apply(lambda x: x.str.lower() if(x.dtype == 'O') else x)\n",
    "    df.shape\n",
    "    time.sleep(3.4)\n",
    "    print(\"\\n ROBO: So to make life easy fo you I have already made a list of some of the popular movies since the 2000s in English, Hindi, Tamil and some other Indian regional languages.\")\n",
    "    print(\"ROBO: \", end='')\n",
    "    time.sleep(2.1)\n",
    "    print(\"So do you have any preferences ?\")\n",
    "    print(\"ROBO: Want to search from your own list?\")\n",
    "\n",
    "    ch = input().lower()\n",
    "    if ('yes' in ch) | ('yea' in ch) | ('ya' in ch) | ('ye' in ch):\n",
    "        # Accepting user input to identify similar movies of their interest\n",
    "        gen = input(\"ROBO: Cool!!\\nEnter Preferred genre(s) (if more than one please use a comma)(Type No if not): \").lower()\n",
    "        df2 = dfm.copy()\n",
    "        if gen != 'no':\n",
    "            df2 = dfm[dfm['genre'].str.contains(gen)]\n",
    "            df2 = df2.drop_duplicates(subset=['title'], keep = False)\n",
    "\n",
    "        lang = input(\"ROBO: Any Preferred Language(s) (if more than one please use a comma)(Type No if not): \").lower()\n",
    "        df3 = df2.copy()\n",
    "        if lang != 'no' :\n",
    "            df3 = df2[df2['language'].str.contains(lang)]\n",
    "            df3 = df3.drop_duplicates(subset = ['title'],keep=False)\n",
    "    else:\n",
    "        print(\"\\nROBO: I see you believe in me :)\")\n",
    "        df3 = df\n",
    "    df3 = df3.sort_values(by=['mean_vote'],ascending = False)\n",
    "    if df3.shape[0] > 10000:\n",
    "        df3 = df3[:10000]\n",
    "    if df3.shape[0] == 0:\n",
    "        print(\"ROBO: I'm sorry but you have not selected any movies. Please try again\")\n",
    "    df3.shape\n",
    "\n",
    "    df3.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    df3['Key_words'] = ''\n",
    "    r = Rake()\n",
    "    for index, row in df3.iterrows():\n",
    "        r.extract_keywords_from_text(row['description'])\n",
    "        key_words_dict_scores = r.get_word_degrees()\n",
    "        row['Key_words'] = list(key_words_dict_scores.keys())\n",
    "        df3['Key_words'][index] = row['Key_words']\n",
    "\n",
    "    df3['genre'] = df3['genre'].map(lambda x: x.split(','))\n",
    "    for index, row in df3.iterrows():\n",
    "        row['genre'] = [x.lower().replace(' ','') for x in row['genre']]\n",
    "\n",
    "    df3['Bag_of_words'] = ''\n",
    "    columns = ['Key_words', 'genre']\n",
    "    for index, row in df3.iterrows():\n",
    "        words = ''\n",
    "        for col in columns:\n",
    "            words += ' '.join(row[col]) + ' '\n",
    "        row['Bag_of_words'] = words\n",
    "        df3['Bag_of_words'][index] = words\n",
    "        dfn = df3[['title','Bag_of_words']]\n",
    "\n",
    "    count = CountVectorizer()\n",
    "    count_matrix = count.fit_transform(dfn['Bag_of_words'])\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    def cosine_similarity_n_space(m1, m2, batch_size=10000):\n",
    "        assert m1.shape[1] == m2.shape[1]\n",
    "        ret = np.ndarray((m1.shape[0], m2.shape[0]))\n",
    "        for row_i in range(0, int(m1.shape[0] / batch_size) + 1):\n",
    "            start = row_i * batch_size\n",
    "            end = min([(row_i + 1) * batch_size, m1.shape[0]])\n",
    "            if end <= start:\n",
    "                break # cause I'm too lazy to elegantly handle edge cases\n",
    "            rows = m1[start: end]\n",
    "            sim = cosine_similarity(rows, m2) # rows is O(1) size\n",
    "            ret[start: end] = sim\n",
    "        return ret\n",
    "\n",
    "    csmain = cosine_similarity_n_space(count_matrix, count_matrix)\n",
    "    dfn = df3[['title','Bag_of_words']]\n",
    "    count = CountVectorizer()\n",
    "    count_matrix = count.fit_transform(dfn['Bag_of_words'])\n",
    "    csmain = cosine_similarity_n_space(count_matrix, count_matrix)\n",
    "    indices = pd.Series(dfn['title'])\n",
    "    def recommend(title, num=10, cosine_sim = csmain):\n",
    "        recommended_movies = []\n",
    "        try:\n",
    "            idx = indices[indices == title].index[0]\n",
    "            score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "            top_10_indices = list(score_series.iloc[1:num+1].index)\n",
    "\n",
    "            for i in top_10_indices:\n",
    "                recommended_movies.append(list(dfn['title'])[i])\n",
    "            print(\"\\nGreat Choice. Here is the list of similar movies:\")\n",
    "            for i in recommended_movies:\n",
    "                print(i.title())\n",
    "            return False\n",
    "        except:\n",
    "            print(\"ROBO: I'm sorry but I could not find such a movie in our Database.\")\n",
    "            print(\"ROBO: I'd recommend you to check the spelling of the movie you entered.\")\n",
    "            print(\"ROBO: Also make sure it belongs to the same genre and language you had entered before.\")\n",
    "            return True\n",
    "\n",
    "    ans = True\n",
    "    while (ans):\n",
    "        print(\"ROBO: Please refer to Imdb for the exact movie Name.\")\n",
    "        user_res = input(\"Enter the movie which you have in mind.\").lower()\n",
    "        num = int(input(\"How many such similar movies do you want??\"))\n",
    "        ans = recommend(user_res,num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeledTrainData.tsv\",sep=\"\\t\")\n",
    "data.head()\n",
    "X = data.review\n",
    "y = data.sentiment\n",
    "#Using CountVectorizer to convert text into tokens/features\n",
    "vect = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size= 0.2)\n",
    "#Using training data to transform text into counts of features for each message\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_dtm, y_train)\n",
    "y_pred = NB.predict(X_test_dtm)\n",
    "#print('\\nNaive Bayes')\n",
    "#print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "#print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "\n",
    "tokens_words = vect.get_feature_names()\n",
    "#print('\\nAnalysis')\n",
    "#print('No. of tokens: ',len(tokens_words))\n",
    "counts = NB.feature_count_\n",
    "df_table = {'Token':tokens_words,'Negative': counts[0,:],'Positive': counts[1,:]}\n",
    "tokens = pd.DataFrame(df_table, columns= ['Token','Positive','Negative'])\n",
    "positives = len(tokens[tokens['Positive']>tokens['Negative']])\n",
    "#print('No. of positive tokens: ',positives)\n",
    "#print('No. of negative tokens: ',len(tokens_words)-positives)\n",
    "#Check positivity/negativity of specific tokens\n",
    "token_search = ['horrendous']\n",
    "#print('\\nSearch Results for token/s:',token_search)\n",
    "#print(tokens.loc[tokens['Token'].isin(token_search)])\n",
    "#Analyse False Negatives (Actual: 1; Predicted: 0)(Predicted negative review for a positive review) \n",
    "#print(X_test[ y_pred < y_test ])\n",
    "#Analyse False Positives (Actual: 0; Predicted: 1)(Predicted positive review for a negative review) \n",
    "#print(X_test[ y_pred > y_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: Hi there\n",
      "ROBO: My name is Robo. Type 'help' for guidance, 'review' to review a movie and let others know your opinion, 'recommend' so we can recommend you a movie based on your preference :)\n",
      "recommend\n",
      "ROBO: Alright...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ab8e6473d281>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'recommend'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter a movie based on which we could recommend one to you: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Similar movies are\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ROBO: Hi there\")\n",
    "print(\"ROBO: My name is Robo. Type 'help' for guidance, 'review' to review a movie and let others know your opinion, 'recommend' so we can recommend you a movie based on your preference :)\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='recommend'):\n",
    "        if(user_response!='review'):\n",
    "            if(user_response=='thanks' or user_response=='thank you' ):\n",
    "                flag=False\n",
    "                print(\"ROBO: You are welcome..\")\n",
    "            else:\n",
    "                if(greeting(user_response)!=None):\n",
    "                    print(\"ROBO: \"+greeting(user_response))\n",
    "                else:\n",
    "                    print(\"ROBO: \",end=\"\")\n",
    "                    print(response(user_response))\n",
    "                    sent_tokens.remove(user_response)\n",
    "        else:\n",
    "            flag=False\n",
    "            print(\"ROBO: Alright...\")  \n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Alright...\")    \n",
    "        \n",
    "if(user_response=='recommend'):\n",
    "    string = input(\"Enter a movie based on which we could recommend one to you: \")\n",
    "    print(\"Similar movies are\")\n",
    "    string = string.lower()\n",
    "    #recommend(string)\n",
    "    print(recommend(string))\n",
    "elif(user_response=='review'):\n",
    "    trainingVector = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 5)\n",
    "    trainingVector.fit(X)\n",
    "    X_dtm = trainingVector.transform(X)\n",
    "    NB_complete = MultinomialNB()\n",
    "    NB_complete.fit(X_dtm, y)\n",
    "    #Input Review\n",
    "    print('\\nTest a custom review message')\n",
    "    print('Enter review to be analysed: ', end=\" \")\n",
    "    test = []\n",
    "    test.append(input())\n",
    "    test_dtm = trainingVector.transform(test)\n",
    "    predLabel = NB_complete.predict(test_dtm)\n",
    "    tags = ['Negative','Positive']\n",
    "    #Display Output\n",
    "    print('The review is predicted:',tags[predLabel[0]])\n",
    "else:\n",
    "    print('Bye! Have a good day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
